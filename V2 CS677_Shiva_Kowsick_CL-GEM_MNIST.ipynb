{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hShHlhTpjbL2"
   },
   "source": [
    "# MNIST PROJECT WORK AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rHK966dKiGPL",
    "outputId": "ee45f5ec-019c-4760-debd-322baa2dba2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "1oMQVwWKruu0"
   },
   "outputs": [],
   "source": [
    "MY_PYTHON=\"!python\" #TODO: modified to add\n",
    "MNIST_ROTA=\"--n_layers 2 --n_hiddens 100 --data_path data/ --save_path results/ --batch_size 20 --log_every 100 --samples_per_task 1000 --data_file mnist_rotations.pt    --cuda no  --seed 0\"\n",
    "MNIST_PERM=\"--n_layers 2 --n_hiddens 100 --data_path data/ --save_path results/ --batch_size 20 --log_every 100 --samples_per_task 1000 --data_file mnist_permutations.pt --cuda no  --seed 0\"\n",
    "CIFAR_100i=\"--n_layers 2 --n_hiddens 100 --data_path data/ --save_path results/ --batch_size 20 --log_every 100 --samples_per_task 2500 --data_file cifar100.pt           --cuda yes --seed 0\"  # TODO: MODIFIED CHECK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 31
    },
    "id": "6qs3rJGci3bH",
    "outputId": "efdf2683-cc63-44b1-eb6b-f53786968bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: '/content/drive/My\\\\ Drive/DL'\n",
      "C:\\Users\\Kowsick\\Downloads\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 45
    },
    "id": "iusn_FmalZ9W",
    "outputId": "db183072-389b-4e90-d2fb-d3f89475732c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsick\\Downloads\\GradientEpisodicMemory\\data\n",
      "C:\\Users\\Kowsick\\Downloads\\GradientEpisodicMemory\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "# build datasets\n",
    "%cd data/\n",
    "%cd raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKvUCeczUxAs"
   },
   "source": [
    "# DOWNLOADING CIFAR and split in to MNIST TRAIN AND TEST DATASET\n",
    "# Executing Raw.py\n",
    "\n",
    "\n",
    "*   Downloading Data - cifar-100-python.tar.gz,  mnist.npz\n",
    "*   Output mnist_train.pt and mnist_test.pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kuXYI1EcU3UX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'ntpath' from 'C:\\\\Users\\\\Kowsick\\\\Anaconda3\\\\lib\\\\ntpath.py'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "\n",
    "cifar_path = \"cifar-100-python.tar.gz\"\n",
    "mnist_path = \"mnist.npz\"\n",
    "\n",
    "# URL from: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "if not os.path.exists(cifar_path):\n",
    "    print(os.path)\n",
    "    subprocess.call(\"wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\", shell=True)\n",
    "\n",
    "subprocess.call(\"tar xzfv cifar-100-python.tar.gz\", shell=True)\n",
    "\n",
    "# URL from: https://github.com/fchollet/keras/blob/master/keras/datasets/mnist.py\n",
    "if not os.path.exists(mnist_path):\n",
    "    subprocess.call(\"wget https://s3.amazonaws.com/img-datasets/mnist.npz\", shell=True)\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "cifar100_train = unpickle('cifar-100-python/train')\n",
    "cifar100_test = unpickle('cifar-100-python/test')\n",
    "\n",
    "x_tr = torch.from_numpy(cifar100_train[b'data'])\n",
    "y_tr = torch.LongTensor(cifar100_train[b'fine_labels'])\n",
    "x_te = torch.from_numpy(cifar100_test[b'data'])\n",
    "y_te = torch.LongTensor(cifar100_test[b'fine_labels'])\n",
    "\n",
    "torch.save((x_tr, y_tr, x_te, y_te), 'cifar100.pt')\n",
    "\n",
    "f = np.load('mnist.npz')\n",
    "x_tr = torch.from_numpy(f['x_train'])\n",
    "y_tr = torch.from_numpy(f['y_train']).long()\n",
    "x_te = torch.from_numpy(f['x_test'])\n",
    "y_te = torch.from_numpy(f['y_test']).long()\n",
    "f.close()\n",
    "\n",
    "torch.save((x_tr, y_tr), 'mnist_train.pt')\n",
    "torch.save((x_te, y_te), 'mnist_test.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YMIGMEZRl81D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'raw.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#import raw\n",
    "!python raw.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cxl8HNpWuez"
   },
   "source": [
    "# DOWNLOADING MNIST PERMUTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 31
    },
    "id": "FPX_ojSHmN5l",
    "outputId": "992ce662-cf01-446c-f294-3e6b45cc2c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsick\\Downloads\\GradientEpisodicMemory\\data\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Nbz5Rg_ZW5vi"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--i', default='raw/', help='input directory')\n",
    "parser.add_argument('--o', default='mnist_permutations.pt', help='output file')\n",
    "parser.add_argument('--n_tasks', default=3, type=int, help='number of tasks')\n",
    "parser.add_argument('--seed', default=0, type=int, help='random seed')\n",
    "args = parser.parse_args(args=[]) #TODO: MODIFIED CHECK\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "tasks_tr = []\n",
    "tasks_te = []\n",
    "\n",
    "x_tr, y_tr = torch.load(os.path.join(args.i, 'mnist_train.pt'))\n",
    "x_te, y_te = torch.load(os.path.join(args.i, 'mnist_test.pt'))\n",
    "x_tr = x_tr.float().view(x_tr.size(0), -1) / 255.0\n",
    "x_te = x_te.float().view(x_te.size(0), -1) / 255.0\n",
    "y_tr = y_tr.view(-1).long()\n",
    "y_te = y_te.view(-1).long()\n",
    "\n",
    "for t in range(args.n_tasks):\n",
    "    p = torch.randperm(x_tr.size(1)).long().view(-1)\n",
    "\n",
    "    tasks_tr.append(['random permutation', x_tr.index_select(1, p), y_tr])\n",
    "    tasks_te.append(['random permutation', x_te.index_select(1, p), y_te])\n",
    "\n",
    "torch.save([tasks_tr, tasks_te], args.o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sSssWVjrpBLi"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-d6f242f7381b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-d6f242f7381b>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    MY_PYTHON mnist_permutations.py \\\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#pwd\n",
    "$MY_PYTHON mnist_permutations.py \\\n",
    "\t--o mnist_permutations.pt \\\n",
    "\t--seed 0 \\\n",
    "\t--n_tasks 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8txbUlbOXbK6"
   },
   "source": [
    "# DOWNLOADING MNIST ROTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aIMibGUeXmYm"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os.path\n",
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "def rotate_dataset(d, rotation):\n",
    "    result = torch.FloatTensor(d.size(0), 784)\n",
    "    tensor = transforms.ToTensor()\n",
    "\n",
    "    for i in range(d.size(0)):\n",
    "        img = Image.fromarray(d[i].numpy(), mode='L')\n",
    "        result[i] = tensor(img.rotate(rotation)).view(784)\n",
    "    return result\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--i', default='raw/', help='input directory')\n",
    "parser.add_argument('--o', default='mnist_rotations.pt', help='output file')\n",
    "parser.add_argument('--n_tasks', default=10, type=int, help='number of tasks')\n",
    "parser.add_argument('--min_rot', default=0.,\n",
    "                    type=float, help='minimum rotation')\n",
    "parser.add_argument('--max_rot', default=90.,\n",
    "                    type=float, help='maximum rotation')\n",
    "parser.add_argument('--seed', default=0, type=int, help='random seed')\n",
    "\n",
    "args = parser.parse_args(args=[]) #TODO : MODIFIED CHECK\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "tasks_tr = []\n",
    "tasks_te = []\n",
    "\n",
    "x_tr, y_tr = torch.load(os.path.join(args.i, 'mnist_train.pt'))\n",
    "x_te, y_te = torch.load(os.path.join(args.i, 'mnist_test.pt'))\n",
    "\n",
    "for t in range(args.n_tasks):\n",
    "    min_rot = 1.0 * t / args.n_tasks * (args.max_rot - args.min_rot) + \\\n",
    "        args.min_rot\n",
    "    max_rot = 1.0 * (t + 1) / args.n_tasks * \\\n",
    "        (args.max_rot - args.min_rot) + args.min_rot\n",
    "    rot = random.random() * (max_rot - min_rot) + min_rot\n",
    "\n",
    "    tasks_tr.append([rot, rotate_dataset(x_tr, rot), y_tr])\n",
    "    tasks_te.append([rot, rotate_dataset(x_te, rot), y_te])\n",
    "\n",
    "torch.save([tasks_tr, tasks_te], args.o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OReMYe7Zq501"
   },
   "outputs": [],
   "source": [
    "!python mnist_rotations.py \\\n",
    "\t--o mnist_rotations.pt\\\n",
    "\t--seed 0 \\\n",
    "\t--min_rot 0 \\\n",
    "\t--max_rot 180 \\\n",
    "\t--n_tasks 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MvTRfJvbD7T"
   },
   "source": [
    "# PROCESSING CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "4K5J8BO5bRyO",
    "outputId": "b1871be7-0fec-4207-bce6-d574e9b432d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsick\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os.path\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--i', default='raw/cifar100.pt', help='input directory')\n",
    "parser.add_argument('--o', default='cifar100.pt', help='output file')\n",
    "parser.add_argument('--n_tasks', default=10, type=int, help='number of tasks')\n",
    "parser.add_argument('--seed', default=0, type=int, help='random seed')\n",
    "args = parser.parse_args(args=[]) #TODO : MODIFIED CHECK\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "tasks_tr = []\n",
    "tasks_te = []\n",
    "\n",
    "x_tr, y_tr, x_te, y_te = torch.load(os.path.join(args.i))\n",
    "x_tr = x_tr.float().view(x_tr.size(0), -1) / 255.0\n",
    "x_te = x_te.float().view(x_te.size(0), -1) / 255.0\n",
    "\n",
    "cpt = int(100 / args.n_tasks)\n",
    "\n",
    "for t in range(args.n_tasks):\n",
    "    c1 = t * cpt\n",
    "    c2 = (t + 1) * cpt\n",
    "    i_tr = ((y_tr >= c1) & (y_tr < c2)).nonzero().view(-1)\n",
    "    i_te = ((y_te >= c1) & (y_te < c2)).nonzero().view(-1)\n",
    "    tasks_tr.append([(c1, c2), x_tr[i_tr].clone(), y_tr[i_tr].clone()])\n",
    "    tasks_te.append([(c1, c2), x_te[i_te].clone(), y_te[i_te].clone()])\n",
    "\n",
    "torch.save([tasks_tr, tasks_te], args.o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcFbFJKtr6Bx",
    "outputId": "3bae0427-7a1f-457d-cda9-df890bc274fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar100.py:33: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  i_tr = ((y_tr >= c1) & (y_tr < c2)).nonzero().view(-1)\n"
     ]
    }
   ],
   "source": [
    "!python cifar100.py \\\n",
    "\t--o cifar100.pt \\\n",
    "\t--seed 0 \\\n",
    "\t--n_tasks 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN4bXrv9cT3P"
   },
   "source": [
    "# MAIN : STOCHASTIC GRADIENT DESCENT - CONTINUAL LEARNING\n",
    "# MODELS\n",
    "\n",
    "\n",
    "1.   Single\n",
    "2.   Multimodal\n",
    "3. independent\n",
    "4.icarl\n",
    "5.gem\n",
    "6.ewc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 31
    },
    "id": "khqKfx9bsTF4",
    "outputId": "8b6e6783-fbff-4ba7-9afb-9f65f3eb5342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsick\\Downloads\\GradientEpisodicMemory\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "iF82WxiXcNT5",
    "outputId": "1f14bb42-ab4f-4f0c-ebd7-7d6fcd764816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/single_mnist_permutations.pt_2020_10_16_22_17_05_aae7a6f3c1ba4381801badd8eef29a38: {'model': 'single', 'n_hiddens': 100, 'n_layers': 2, 'n_memories': 0, 'memory_strength': 0, 'finetune': False, 'n_epochs': 1, 'batch_size': 10, 'lr': 0.001, 'cuda': False, 'seed': 0, 'log_every': 100, 'save_path': 'results/', 'data_path': 'data/', 'data_file': 'mnist_permutations.pt', 'samples_per_task': -1, 'shuffle_tasks': 'no'} # 0.832 -0.049 -0.010 # 60.447291135787964\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import datetime\n",
    "import argparse\n",
    "import random\n",
    "import uuid\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from metrics.metrics import confusion_matrix\n",
    "\n",
    "# continuum iterator #########################################################\n",
    "\n",
    "\n",
    "def load_datasets(args):\n",
    "    d_tr, d_te = torch.load(args.data_path + '/' + args.data_file)\n",
    "    n_inputs = d_tr[0][1].size(1)\n",
    "    n_outputs = 0\n",
    "    for i in range(len(d_tr)):\n",
    "        n_outputs = max(n_outputs, d_tr[i][2].max().item())\n",
    "        n_outputs = max(n_outputs, d_te[i][2].max().item())\n",
    "    return d_tr, d_te, n_inputs, n_outputs + 1, len(d_tr)\n",
    "\n",
    "\n",
    "class Continuum:\n",
    "\n",
    "    def __init__(self, data, args):\n",
    "        self.data = data\n",
    "        self.batch_size = args.batch_size\n",
    "        n_tasks = len(data)\n",
    "        task_permutation = range(n_tasks)\n",
    "\n",
    "        if args.shuffle_tasks == 'yes':\n",
    "            task_permutation = torch.randperm(n_tasks).tolist()\n",
    "\n",
    "        sample_permutations = []\n",
    "\n",
    "        for t in range(n_tasks):\n",
    "            N = data[t][1].size(0)\n",
    "            if args.samples_per_task <= 0:\n",
    "                n = N\n",
    "            else:\n",
    "                n = min(args.samples_per_task, N)\n",
    "\n",
    "            p = torch.randperm(N)[0:n]\n",
    "            sample_permutations.append(p)\n",
    "\n",
    "        self.permutation = []\n",
    "\n",
    "        for t in range(n_tasks):\n",
    "            task_t = task_permutation[t]\n",
    "            for _ in range(args.n_epochs):\n",
    "                task_p = [[task_t, i] for i in sample_permutations[task_t]]\n",
    "                random.shuffle(task_p)\n",
    "                self.permutation += task_p\n",
    "\n",
    "        self.length = len(self.permutation)\n",
    "        self.current = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current >= self.length:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            ti = self.permutation[self.current][0]\n",
    "            j = []\n",
    "            i = 0\n",
    "            while (((self.current + i) < self.length) and\n",
    "                   (self.permutation[self.current + i][0] == ti) and\n",
    "                   (i < self.batch_size)):\n",
    "                j.append(self.permutation[self.current + i][1])\n",
    "                i += 1\n",
    "            self.current += i\n",
    "            j = torch.LongTensor(j)\n",
    "            return self.data[ti][1][j], ti, self.data[ti][2][j]\n",
    "\n",
    "# train handle ###############################################################\n",
    "\n",
    "\n",
    "def eval_tasks(model, tasks, args):\n",
    "    model.eval()\n",
    "    result = []\n",
    "    for i, task in enumerate(tasks):\n",
    "        t = i\n",
    "        x = task[1]\n",
    "        y = task[2]\n",
    "        rt = 0\n",
    "        \n",
    "        eval_bs = x.size(0)\n",
    "\n",
    "        for b_from in range(0, x.size(0), eval_bs):\n",
    "            b_to = min(b_from + eval_bs, x.size(0) - 1)\n",
    "            if b_from == b_to:\n",
    "                xb = x[b_from].view(1, -1)\n",
    "                yb = torch.LongTensor([y[b_to]]).view(1, -1)\n",
    "            else:\n",
    "                xb = x[b_from:b_to]\n",
    "                yb = y[b_from:b_to]\n",
    "            if args.cuda:\n",
    "                xb = xb.cuda()\n",
    "            _, pb = torch.max(model(xb, t).data.cpu(), 1, keepdim=False)\n",
    "            rt += (pb == yb).float().sum()\n",
    "\n",
    "        result.append(rt / x.size(0))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def life_experience(model, continuum, x_te, args):\n",
    "    result_a = []\n",
    "    result_t = []\n",
    "\n",
    "    current_task = 0\n",
    "    time_start = time.time()\n",
    "\n",
    "    for (i, (x, t, y)) in enumerate(continuum):\n",
    "        if(((i % args.log_every) == 0) or (t != current_task)):\n",
    "            result_a.append(eval_tasks(model, x_te, args))\n",
    "            result_t.append(current_task)\n",
    "            current_task = t\n",
    "\n",
    "        v_x = x.view(x.size(0), -1)\n",
    "        v_y = y.long()\n",
    "\n",
    "        if args.cuda:\n",
    "            v_x = v_x.cuda()\n",
    "            v_y = v_y.cuda()\n",
    "\n",
    "        model.train()\n",
    "        model.observe(v_x, t, v_y)\n",
    "\n",
    "    result_a.append(eval_tasks(model, x_te, args))\n",
    "    result_t.append(current_task)\n",
    "\n",
    "    time_end = time.time()\n",
    "    time_spent = time_end - time_start\n",
    "\n",
    "    return torch.Tensor(result_t), torch.Tensor(result_a), time_spent\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Continuum learning')\n",
    "\n",
    "    # model parameters\n",
    "    parser.add_argument('--model', type=str, default='single',\n",
    "                        help='model to train')\n",
    "    parser.add_argument('--n_hiddens', type=int, default=100,\n",
    "                        help='number of hidden neurons at each layer')\n",
    "    parser.add_argument('--n_layers', type=int, default=2,\n",
    "                        help='number of hidden layers')\n",
    "\n",
    "    # memory parameters\n",
    "    parser.add_argument('--n_memories', type=int, default=0,\n",
    "                        help='number of memories per task')\n",
    "    parser.add_argument('--memory_strength', default=0, type=float,\n",
    "                        help='memory strength (meaning depends on memory)')\n",
    "    parser.add_argument('--finetune', default='no', type=str,\n",
    "                        help='whether to initialize nets in indep. nets')\n",
    "\n",
    "    # optimizer parameters\n",
    "    parser.add_argument('--n_epochs', type=int, default=1,\n",
    "                        help='Number of epochs per task')\n",
    "    parser.add_argument('--batch_size', type=int, default=10,\n",
    "                        help='batch size')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                        help='SGD learning rate')\n",
    "\n",
    "    # experiment parameters\n",
    "    parser.add_argument('--cuda', type=str, default='no',\n",
    "                        help='Use GPU?')\n",
    "    parser.add_argument('--seed', type=int, default=0,\n",
    "                        help='random seed')\n",
    "    parser.add_argument('--log_every', type=int, default=100,\n",
    "                        help='frequency of logs, in minibatches')\n",
    "    parser.add_argument('--save_path', type=str, default='results/',\n",
    "                        help='save models at the end of training')\n",
    "\n",
    "    # data parameters\n",
    "    parser.add_argument('--data_path', default='data/',\n",
    "                        help='path where data is located')\n",
    "    parser.add_argument('--data_file', default='mnist_permutations.pt',\n",
    "                        help='data file')\n",
    "    parser.add_argument('--samples_per_task', type=int, default=-1,\n",
    "                        help='training samples per task (all if negative)')\n",
    "    parser.add_argument('--shuffle_tasks', type=str, default='no',\n",
    "                        help='present tasks in order')\n",
    "    args = parser.parse_args(args=[]) # TODO : MODIFIED CHECK\n",
    "\n",
    "    args.cuda = True if args.cuda == 'yes' else False\n",
    "    args.finetune = True if args.finetune == 'yes' else False\n",
    "\n",
    "    # multimodal model has one extra layer\n",
    "    if args.model == 'multimodal':\n",
    "        args.n_layers -= 1\n",
    "\n",
    "    # unique identifier\n",
    "    uid = uuid.uuid4().hex\n",
    "\n",
    "    # initialize seeds\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    # load data\n",
    "    x_tr, x_te, n_inputs, n_outputs, n_tasks = load_datasets(args)\n",
    "\n",
    "    # set up continuum\n",
    "    continuum = Continuum(x_tr, args)\n",
    "\n",
    "    # load model\n",
    "    Model = importlib.import_module('model.' + args.model)\n",
    "    model = Model.Net(n_inputs, n_outputs, n_tasks, args)\n",
    "    if args.cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    # run model on continuum\n",
    "    result_t, result_a, spent_time = life_experience(\n",
    "        model, continuum, x_te, args)\n",
    "\n",
    "    # prepare saving path and file name\n",
    "    if not os.path.exists(args.save_path):\n",
    "        os.makedirs(args.save_path)\n",
    "\n",
    "    fname = args.model + '_' + args.data_file + '_'\n",
    "    fname += datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    fname += '_' + uid\n",
    "    fname = os.path.join(args.save_path, fname)\n",
    "\n",
    "    # save confusion matrix and print one line of stats\n",
    "    stats = confusion_matrix(result_t, result_a, fname + '.txt')\n",
    "    one_liner = str(vars(args)) + ' # '\n",
    "    one_liner += ' '.join([\"%.3f\" % stat for stat in stats])\n",
    "    print(fname + ': ' + one_liner + ' # ' + str(spent_time))\n",
    "\n",
    "    # save all results in binary file\n",
    "    torch.save((result_t, result_a, model.state_dict(),\n",
    "                stats, one_liner, args), fname + '.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPpuKJ8Ybown"
   },
   "source": [
    "# TRAINING MNIST ROTATIONS DATA SET : SINGLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsick\\Downloads\\GradientEpisodicMemory\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4q9HeJTscrR",
    "outputId": "99c23ecc-fa76-4928-bbc6-e7221bd6b02f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/single_mnist_rotations.pt_2020_10_17_07_20_06_370febf27ec947edadfb2806c904bc85: {'model': 'single', 'n_hiddens': 100, 'n_layers': 2, 'n_memories': 0, 'memory_strength': 0, 'finetune': False, 'n_epochs': 1, 'batch_size': 20, 'lr': 0.001, 'cuda': False, 'seed': 0, 'log_every': 100, 'save_path': 'results/', 'data_path': 'data/', 'data_file': 'mnist_rotations.pt', 'samples_per_task': 1000, 'shuffle_tasks': 'no'} # 0.172 0.043 0.028 # 5.11372709274292\n"
     ]
    }
   ],
   "source": [
    "!python main.py $MNIST_ROTA --model single --lr 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bptR9HpufsHi"
   },
   "source": [
    "# TRAINING MNIST PERMUATATIONS DATA SET : SINGLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66DAXknXvFj1",
    "outputId": "17dd17a1-41d2-4862-be0d-d2cfaa8d31c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/single_mnist_permutations.pt_2020_10_17_07_20_20_3cf52d23bb584f3d8fe15fa7e4ac1671: {'model': 'single', 'n_hiddens': 100, 'n_layers': 2, 'n_memories': 0, 'memory_strength': 0, 'finetune': False, 'n_epochs': 1, 'batch_size': 20, 'lr': 0.01, 'cuda': False, 'seed': 0, 'log_every': 100, 'save_path': 'results/', 'data_path': 'data/', 'data_file': 'mnist_permutations.pt', 'samples_per_task': 1000, 'shuffle_tasks': 'no'} # 0.338 0.010 -0.013 # 1.0768365859985352\n"
     ]
    }
   ],
   "source": [
    "!python main.py $MNIST_PERM --model single --lr 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B68Om0Xef_Fz"
   },
   "source": [
    "# TRAINING CIFAR 100 :SINGLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iCBvWrhQvh3N",
    "outputId": "956bd694-01af-4bdc-e699-66cfef9ade8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/single_cifar100.pt_2020_10_17_07_36_01_bc63d524435b466b85db880fff8955c4: {'model': 'single', 'n_hiddens': 100, 'n_layers': 2, 'n_memories': 0, 'memory_strength': 0, 'finetune': False, 'n_epochs': 1, 'batch_size': 20, 'lr': 0.1, 'cuda': True, 'seed': 0, 'log_every': 100, 'save_path': 'results/', 'data_path': 'data/', 'data_file': 'cifar100.pt', 'samples_per_task': 2500, 'shuffle_tasks': 'no'} # 0.277 -0.105 0.006 # 914.3273599147797\n"
     ]
    }
   ],
   "source": [
    "!python main.py $CIFAR_100i --model single --lr 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM6zlC_eg0Qf"
   },
   "source": [
    "# TRAINING WITH VARIOUS MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zcZRuEargk4x"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-c048b802af96>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-c048b802af96>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    $MY_PYTHON main.py $MNIST_ROTA --model independent --lr 0.1  --finetune yes\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# model \"independent\"\n",
    "$MY_PYTHON main.py $MNIST_ROTA --model independent --lr 0.1  --finetune yes \n",
    "$MY_PYTHON main.py $MNIST_PERM --model independent --lr 0.03 --finetune yes \n",
    "$MY_PYTHON main.py $CIFAR_100i --model independent --lr 0.3  --finetune yes \n",
    "\n",
    "# model \"multimodal\"\n",
    "$MY_PYTHON main.py $MNIST_ROTA  --model multimodal --lr 0.1\n",
    "$MY_PYTHON main.py $MNIST_PERM  --model multimodal --lr 0.1\n",
    "\n",
    "# model \"EWC\"\n",
    "$MY_PYTHON main.py $MNIST_ROTA --model ewc --lr 0.01 --n_memories 1000 --memory_strength 1000\n",
    "$MY_PYTHON main.py $MNIST_PERM --model ewc --lr 0.1  --n_memories 10   --memory_strength 3\n",
    "$MY_PYTHON main.py $CIFAR_100i --model ewc --lr 1.0  --n_memories 10   --memory_strength 1\n",
    "\n",
    "# model \"iCARL\"\n",
    "$MY_PYTHON main.py $CIFAR_100i --model icarl --lr 1.0 --n_memories 1280 --memory_strength 1\n",
    "\n",
    "# model \"GEM\"\n",
    "$MY_PYTHON main.py $MNIST_ROTA --model gem --lr 0.1 --n_memories 256 --memory_strength 0.5\n",
    "$MY_PYTHON main.py $MNIST_PERM --model gem --lr 0.1 --n_memories 256 --memory_strength 0.5\n",
    "$MY_PYTHON main.py $CIFAR_100i --model gem --lr 0.1 --n_memories 256 --memory_strength 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsick\\Downloads\\GradientEpisodicMemory\\model\n"
     ]
    }
   ],
   "source": [
    "%cd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsick\\Downloads\\GradientEpisodicMemory\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/gem_mnist_rotations.pt_2020_10_17_07_44_05_ee9090d602ce452589bdceb0e93cf81c: {'model': 'gem', 'n_hiddens': 100, 'n_layers': 2, 'n_memories': 256, 'memory_strength': 0.5, 'finetune': False, 'n_epochs': 1, 'batch_size': 20, 'lr': 0.3, 'cuda': False, 'seed': 0, 'log_every': 100, 'save_path': 'results/', 'data_path': 'data/', 'data_file': 'mnist_rotations.pt', 'samples_per_task': 1000, 'shuffle_tasks': 'no'} # 0.851 0.009 0.625 # 19.74474024772644\n"
     ]
    }
   ],
   "source": [
    "!python main.py $MNIST_ROTA --model gem --lr 0.3 --n_memories 256 --memory_strength 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import quadprog\n",
    "\n",
    "#TODO: modified\n",
    "from common import MLP, ResNet18\n",
    "\n",
    "# Auxiliary functions useful for GEM's inner optimization.\n",
    "\n",
    "def compute_offsets(task, nc_per_task, is_cifar):\n",
    "    \"\"\"\n",
    "        Compute offsets for cifar to determine which\n",
    "        outputs to select for a given task.\n",
    "    \"\"\"\n",
    "    if is_cifar:\n",
    "        offset1 = task * nc_per_task\n",
    "        offset2 = (task + 1) * nc_per_task\n",
    "    else:\n",
    "        offset1 = 0\n",
    "        offset2 = nc_per_task\n",
    "    return offset1, offset2\n",
    "\n",
    "\n",
    "def store_grad(pp, grads, grad_dims, tid):\n",
    "    \"\"\"\n",
    "        This stores parameter gradients of past tasks.\n",
    "        pp: parameters\n",
    "        grads: gradients\n",
    "        grad_dims: list with number of parameters per layers\n",
    "        tid: task id\n",
    "    \"\"\"\n",
    "    # store the gradients\n",
    "    grads[:, tid].fill_(0.0)\n",
    "    cnt = 0\n",
    "    for param in pp():\n",
    "        if param.grad is not None:\n",
    "            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n",
    "            en = sum(grad_dims[:cnt + 1])\n",
    "            grads[beg: en, tid].copy_(param.grad.data.view(-1))\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "def overwrite_grad(pp, newgrad, grad_dims):\n",
    "    \"\"\"\n",
    "        This is used to overwrite the gradients with a new gradient\n",
    "        vector, whenever violations occur.\n",
    "        pp: parameters\n",
    "        newgrad: corrected gradient\n",
    "        grad_dims: list storing number of parameters at each layer\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    for param in pp():\n",
    "        if param.grad is not None:\n",
    "            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n",
    "            en = sum(grad_dims[:cnt + 1])\n",
    "            this_grad = newgrad[beg: en].contiguous().view(\n",
    "                param.grad.data.size())\n",
    "            param.grad.data.copy_(this_grad)\n",
    "        cnt += 1\n",
    "\n",
    "\n",
    "def project2cone2(gradient, memories, margin=0.5, eps=1e-3):\n",
    "    \"\"\"\n",
    "        Solves the GEM dual QP described in the paper given a proposed\n",
    "        gradient \"gradient\", and a memory of task gradients \"memories\".\n",
    "        Overwrites \"gradient\" with the final projected update.\n",
    "\n",
    "        input:  gradient, p-vector\n",
    "        input:  memories, (t * p)-vector\n",
    "        output: x, p-vector\n",
    "    \"\"\"\n",
    "    memories_np = memories.cpu().t().double().numpy()\n",
    "    gradient_np = gradient.cpu().contiguous().view(-1).double().numpy()\n",
    "    t = memories_np.shape[0]\n",
    "    P = np.dot(memories_np, memories_np.transpose())\n",
    "    P = 0.5 * (P + P.transpose()) + np.eye(t) * eps\n",
    "    q = np.dot(memories_np, gradient_np) * -1\n",
    "    G = np.eye(t)\n",
    "    h = np.zeros(t) + margin\n",
    "    v = quadprog.solve_qp(P, q, G, h)[0]\n",
    "    x = np.dot(v, memories_np) + gradient_np\n",
    "    gradient.copy_(torch.Tensor(x).view(-1, 1))\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_inputs,\n",
    "                 n_outputs,\n",
    "                 n_tasks,\n",
    "                 args):\n",
    "        super(Net, self).__init__()\n",
    "        nl, nh = args.n_layers, args.n_hiddens\n",
    "        self.margin = args.memory_strength\n",
    "        self.is_cifar = (args.data_file == 'cifar100.pt')\n",
    "        if self.is_cifar:\n",
    "            self.net = ResNet18(n_outputs)\n",
    "        else:\n",
    "            self.net = MLP([n_inputs] + [nh] * nl + [n_outputs])\n",
    "\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        self.opt = optim.SGD(self.parameters(), args.lr)\n",
    "\n",
    "        self.n_memories = args.n_memories\n",
    "        self.gpu = args.cuda\n",
    "\n",
    "        # allocate episodic memory\n",
    "        self.memory_data = torch.FloatTensor(\n",
    "            n_tasks, self.n_memories, n_inputs)\n",
    "        self.memory_labs = torch.LongTensor(n_tasks, self.n_memories)\n",
    "        if args.cuda:\n",
    "            self.memory_data = self.memory_data.cuda()\n",
    "            self.memory_labs = self.memory_labs.cuda()\n",
    "\n",
    "        # allocate temporary synaptic memory\n",
    "        self.grad_dims = []\n",
    "        for param in self.parameters():\n",
    "            self.grad_dims.append(param.data.numel())\n",
    "        self.grads = torch.Tensor(sum(self.grad_dims), n_tasks)\n",
    "        if args.cuda:\n",
    "            self.grads = self.grads.cuda()\n",
    "\n",
    "        # allocate counters\n",
    "        self.observed_tasks = []\n",
    "        self.old_task = -1\n",
    "        self.mem_cnt = 0\n",
    "        if self.is_cifar:\n",
    "            self.nc_per_task = int(n_outputs / n_tasks)\n",
    "        else:\n",
    "            self.nc_per_task = n_outputs\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        output = self.net(x)\n",
    "        if self.is_cifar:\n",
    "            # make sure we predict classes within the current task\n",
    "            offset1 = int(t * self.nc_per_task)\n",
    "            offset2 = int((t + 1) * self.nc_per_task)\n",
    "            if offset1 > 0:\n",
    "                output[:, :offset1].data.fill_(-10e10)\n",
    "            if offset2 < self.n_outputs:\n",
    "                output[:, offset2:self.n_outputs].data.fill_(-10e10)\n",
    "        return output\n",
    "\n",
    "    def observe(self, x, t, y):\n",
    "        # update memory\n",
    "        if t != self.old_task:\n",
    "            self.observed_tasks.append(t)\n",
    "            self.old_task = t\n",
    "\n",
    "        # Update ring buffer storing examples from current task\n",
    "        bsz = y.data.size(0)\n",
    "        endcnt = min(self.mem_cnt + bsz, self.n_memories)\n",
    "        effbsz = endcnt - self.mem_cnt\n",
    "        self.memory_data[t, self.mem_cnt: endcnt].copy_(\n",
    "            x.data[: effbsz])\n",
    "        if bsz == 1:\n",
    "            self.memory_labs[t, self.mem_cnt] = y.data[0]\n",
    "        else:\n",
    "            self.memory_labs[t, self.mem_cnt: endcnt].copy_(\n",
    "                y.data[: effbsz])\n",
    "        self.mem_cnt += effbsz\n",
    "        if self.mem_cnt == self.n_memories:\n",
    "            self.mem_cnt = 0\n",
    "\n",
    "        # compute gradient on previous tasks\n",
    "        if len(self.observed_tasks) > 1:\n",
    "            for tt in range(len(self.observed_tasks) - 1):\n",
    "                self.zero_grad()\n",
    "                # fwd/bwd on the examples in the memory\n",
    "                past_task = self.observed_tasks[tt]\n",
    "\n",
    "                offset1, offset2 = compute_offsets(past_task, self.nc_per_task,\n",
    "                                                   self.is_cifar)\n",
    "                ptloss = self.ce(\n",
    "                    self.forward(\n",
    "                        self.memory_data[past_task],\n",
    "                        past_task)[:, offset1: offset2],\n",
    "                    self.memory_labs[past_task] - offset1)\n",
    "                ptloss.backward()\n",
    "                store_grad(self.parameters, self.grads, self.grad_dims,\n",
    "                           past_task)\n",
    "\n",
    "        # now compute the grad on the current minibatch\n",
    "        self.zero_grad()\n",
    "\n",
    "        offset1, offset2 = compute_offsets(t, self.nc_per_task, self.is_cifar)\n",
    "        loss = self.ce(self.forward(x, t)[:, offset1: offset2], y - offset1)\n",
    "        loss.backward()\n",
    "\n",
    "        # check if gradient violates constraints\n",
    "        if len(self.observed_tasks) > 1:\n",
    "            # copy gradient\n",
    "            store_grad(self.parameters, self.grads, self.grad_dims, t)\n",
    "            indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n",
    "                else torch.LongTensor(self.observed_tasks[:-1])\n",
    "            dotp = torch.mm(self.grads[:, t].unsqueeze(0),\n",
    "                            self.grads.index_select(1, indx))\n",
    "            if (dotp < 0).sum() != 0:\n",
    "                project2cone2(self.grads[:, t].unsqueeze(1),\n",
    "                              self.grads.index_select(1, indx), self.margin)\n",
    "                # copy gradients back\n",
    "                overwrite_grad(self.parameters, self.grads[:, t],\n",
    "                               self.grad_dims)\n",
    "        self.opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/gem_mnist_permutations.pt_2020_10_17_07_44_29_378cf8a973a743a1a049886400e58798: {'model': 'gem', 'n_hiddens': 100, 'n_layers': 2, 'n_memories': 256, 'memory_strength': 0.5, 'finetune': False, 'n_epochs': 1, 'batch_size': 20, 'lr': 0.3, 'cuda': False, 'seed': 0, 'log_every': 100, 'save_path': 'results/', 'data_path': 'data/', 'data_file': 'mnist_permutations.pt', 'samples_per_task': 1000, 'shuffle_tasks': 'no'} # 0.745 0.029 -0.017 # 2.0036978721618652\n"
     ]
    }
   ],
   "source": [
    "!python main.py $MNIST_PERM --model gem --lr 0.3 --n_memories 256 --memory_strength 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/gem_cifar100.pt_2020_10_17_15_27_32_ebaaa25062cf43249dd2ac88ff963f63: {'model': 'gem', 'n_hiddens': 100, 'n_layers': 2, 'n_memories': 256, 'memory_strength': 0.5, 'finetune': False, 'n_epochs': 1, 'batch_size': 20, 'lr': 0.3, 'cuda': True, 'seed': 0, 'log_every': 100, 'save_path': 'results/', 'data_path': 'data/', 'data_file': 'cifar100.pt', 'samples_per_task': 2500, 'shuffle_tasks': 'no'} # 0.446 0.072 -0.000 # 5714.5298862457275\n"
     ]
    }
   ],
   "source": [
    "!python main.py $CIFAR_100i --model gem --lr 0.3 --n_memories 256 --memory_strength 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPhqBufRgGFF"
   },
   "source": [
    "# RESULTS : EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 31
    },
    "id": "sR_Y7IImugT7",
    "outputId": "b08debf6-5809-4769-a8e6-369d613352c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kowsick\\Downloads\\GradientEpisodicMemory\\results\n"
     ]
    }
   ],
   "source": [
    "%cd results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 31
    },
    "id": "97ZThoH0gVgO",
    "outputId": "95ad26e0-4914-463c-b90e-a9a5c5672bb7"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "\n",
    "# if 'roman' in mpl.font_manager.weight_dict.keys():\n",
    "#     del mpl.font_manager.weight_dict['roman']\n",
    "# mpl.font_manager._rebuild()\n",
    "\n",
    "mpl.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "mpl.rcParams[\"font.family\"] = \"DejaVu Serif\"\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "models = ['single', 'independent', 'multimodal', 'icarl', 'ewc', 'gem']\n",
    "datasets = ['mnist_permutations', 'mnist_rotations', 'cifar100']\n",
    "\n",
    "names_datasets = {'mnist_permutations': 'MNIST permutations',\n",
    "                  'mnist_rotations': 'MNIST rotations',\n",
    "                  'cifar100': 'CIFAR-100'}\n",
    "\n",
    "names_models = {'single': 'single',\n",
    "                'independent': 'independent',\n",
    "                'multimodal': 'multimodal',\n",
    "                'icarl': 'iCARL',\n",
    "                'ewc': 'EWC',\n",
    "                'gem': 'GEM'}\n",
    "\n",
    "colors = {'single': 'C0',\n",
    "          'independent': 'C1',\n",
    "          'multimodal': 'C2',\n",
    "          'icarl': 'C2',\n",
    "          'ewc': 'C3',\n",
    "          'gem': 'C4'}\n",
    "\n",
    "barplot = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    barplot[dataset] = {}\n",
    "    for model in models:\n",
    "        barplot[dataset][model] = {}\n",
    "        matches = glob(model + '*' + dataset + '*.pt')\n",
    "        if len(matches):\n",
    "            data = torch.load(matches[0], map_location=lambda storage, loc: storage)\n",
    "            acc, bwt, fwt = data[3][:]\n",
    "            barplot[dataset][model]['acc'] = acc\n",
    "            barplot[dataset][model]['bwt'] = bwt\n",
    "            barplot[dataset][model]['fwt'] = fwt\n",
    "\n",
    "for dataset in datasets:\n",
    "    x_lab = []\n",
    "    y_acc = []\n",
    "    y_bwt = []\n",
    "    y_fwt = []\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        if barplot[dataset][model] != {}:\n",
    "            x_lab.append(model)\n",
    "            y_acc.append(barplot[dataset][model]['acc'])\n",
    "            y_bwt.append(barplot[dataset][model]['bwt'])\n",
    "            y_fwt.append(barplot[dataset][model]['fwt'])\n",
    "\n",
    "    x_ind = np.arange(len(y_acc))\n",
    "\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    all_colors = []\n",
    "    for xi, yi, li in zip(x_ind, y_acc, x_lab):\n",
    "        plt.bar(xi, yi, label=names_models[li], color=colors[li])\n",
    "        all_colors.append(colors[li])\n",
    "    plt.bar(x_ind + (len(y_acc) + 1) * 1, y_bwt, color=all_colors)\n",
    "    plt.bar(x_ind + (len(y_acc) + 1) * 2, y_fwt, color=all_colors)\n",
    "    plt.xticks([2, 8, 14], ['ACC', 'BWT', 'FWT'], fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xlim(-1, len(y_acc) * 3 + 2)\n",
    "    plt.ylabel('classification accuracy', fontsize=16)\n",
    "    plt.title(names_datasets[dataset], fontsize=16)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('barplot_%s.pdf' % dataset, bbox_inches='tight')\n",
    "    # plt.show()\n",
    "\n",
    "evoplot = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    evoplot[dataset] = {}\n",
    "    for model in models:\n",
    "        matches = glob(model + '*' + dataset + '*.pt')\n",
    "        if len(matches):\n",
    "            data = torch.load(matches[0], map_location=lambda storage, loc: storage)\n",
    "            evoplot[dataset][model] = data[1][:, 0].numpy()\n",
    "\n",
    "for dataset in datasets:\n",
    "\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    for model in models:\n",
    "        if model in evoplot[dataset]:\n",
    "            x = np.arange(len(evoplot[dataset][model]))\n",
    "            x = (x - x.min()) / (x.max() - x.min()) * 20\n",
    "            plt.plot(x, evoplot[dataset][model], color=colors[model], lw=3)\n",
    "            plt.xticks(range(0, 21, 2))\n",
    "\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.xlabel('task number', fontsize=16)\n",
    "    plt.title(names_datasets[dataset], fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('evoplot_%s.pdf' % dataset, bbox_inches='tight')\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_uZCR00uqiL",
    "outputId": "ffd27576-fd3d-4089-e7c1-2d52bbbb499c"
   },
   "outputs": [],
   "source": [
    "!python plot_results.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Shiva_DL",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
